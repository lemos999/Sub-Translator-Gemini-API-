# filename: core.py

# -----------------------------------------------------------------------------
# [1. ì˜ì¡´ì„± ì„í¬íŠ¸]
# ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ë™í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ëª¨ë“  ì™¸ë¶€ ë° ë‚´ë¶€ ëª¨ë“ˆì„ ì„ ì–¸í•œë‹¤.
# -----------------------------------------------------------------------------

# --- ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ---
import streamlit as st                 # ì›¹ UI í”„ë ˆì„ì›Œí¬. í™”ë©´ì˜ ëª¨ë“  ì‹œê°ì  ìš”ì†Œë¥¼ ê·¸ë¦¬ê³  ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•œë‹¤.
import google.generativeai as genai    # Google Gemini AI ëª¨ë¸ê³¼ì˜ í†µì‹ ì„ ë‹´ë‹¹í•˜ëŠ” ê³µì‹ SDK.
import time                            # ì‹œê°„ ê´€ë ¨ í•¨ìˆ˜. API í˜¸ì¶œ ì‚¬ì´ì˜ ì§€ì—°(ë”œë ˆì´)ì´ë‚˜ ì‘ì—… ì†Œìš” ì‹œê°„ì„ ì¸¡ì •í•˜ëŠ” ë° ì‚¬ìš©.
import datetime                        # ë‚ ì§œì™€ ì‹œê°„ ê°ì²´ë¥¼ ë‹¤ë£¨ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬. 'ê²½ê³¼ ì‹œê°„'ì´ë‚˜ 'ì˜ˆìƒ ì¢…ë£Œ ì‹œê°„'ì„ ì‚¬ëŒì´ ë³´ê¸° ì¢‹ì€ í˜•íƒœë¡œ í¬ë§·íŒ…í•œë‹¤.

# --- ë‚´ë¶€ ëª¨ë“ˆ ---
# ìš°ë¦¬ê°€ ì§ì ‘ ê¸°ëŠ¥ë³„ë¡œ ë¶„ë¦¬í•œ ëª¨ë“ˆë“¤ì„ ë¶ˆëŸ¬ì˜¨ë‹¤. (ëª¨ë“ˆí™”ì˜ ì¦ê±°)
import config                          # ê³ ì •ëœ ì„¤ì •ê°’(URL, ì´ë¦„, UI ì˜µì…˜ ë“±)ì„ ëª¨ì•„ë‘” ì„¤ì • íŒŒì¼.
import core                            # UIì™€ ì™„ì „íˆ ë¶„ë¦¬ëœ, ìˆœìˆ˜ ë²ˆì—­ ë¡œì§ì˜ í•µì‹¬ ì—”ì§„.
import ui                              # ë³µì¡í•œ UI ì»´í¬ë„ŒíŠ¸(ì‚¬ì´ë“œë°”, ê·¸ë¦¬ë“œ ë“±)ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ë“¤ì˜ ì§‘í•©.


# -----------------------------------------------------------------------------
# [2. ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒíƒœ ê´€ë¦¬]
# Streamlitì˜ í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜ì¸ 'ì¬ì‹¤í–‰(rerun)'ì— ëŒ€ì‘í•˜ê¸° ìœ„í•œ ìƒíƒœ ê´€ë¦¬.
# -----------------------------------------------------------------------------

def init_session_state():
    """
    ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ëª¨ë“  ìƒíƒœ ë³€ìˆ˜ë¥¼ ì´ˆê¸°í™”í•œë‹¤.
    Streamlitì€ ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ì‹œ ìŠ¤í¬ë¦½íŠ¸ ì „ì²´ë¥¼ ì¬ì‹¤í–‰í•˜ë¯€ë¡œ, ë³€ìˆ˜ ê°’ì´ ì´ˆê¸°í™”ë˜ëŠ” ê²ƒì„ ë§‰ê¸° ìœ„í•´
    st.session_state ë¼ëŠ” íŠ¹ë³„í•œ 'ê¸°ì–µ ê³µê°„' ë˜ëŠ” 'ê¸ˆê³ 'ì— ë°ì´í„°ë¥¼ ë³´ê´€í•´ì•¼ í•œë‹¤.
    ì´ í•¨ìˆ˜ëŠ” ì•±ì´ ì²˜ìŒ ì‹¤í–‰ë  ë•Œ í•„ìš”í•œ ëª¨ë“  'ê¸ˆê³ 'ì˜ ì¹¸ì„ ë¯¸ë¦¬ ë§Œë“¤ì–´ë‘ëŠ” ì—­í• ì„ í•œë‹¤.
    """
    # ì• í”Œë¦¬ì¼€ì´ì…˜ ì „ì—­ì—ì„œ ì‚¬ìš©ë  ëª¨ë“  ìƒíƒœ ë³€ìˆ˜ì™€ ê·¸ ê¸°ë³¸ê°’ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ì •ì˜.
    defaults = {
        "chunks": [],                   # ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ë‚˜ëˆˆ ì²­í¬ë“¤ì˜ ë¦¬ìŠ¤íŠ¸.
        "results": [],                  # ê° ì²­í¬ì˜ ë²ˆì—­ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸.
        "debugs": [],                   # ê° ì²­í¬ì˜ ìƒì„¸ ë””ë²„ê·¸ ì •ë³´ ë¦¬ìŠ¤íŠ¸.
        "parsed_srt": [],               # ì›ë³¸ SRT íŒŒì¼ì„ íŒŒì‹±í•œ êµ¬ì¡°ì²´ ë¦¬ìŠ¤íŠ¸.
        "chunk_states": [],             # UI ì‹œê°í™”ë¥¼ ìœ„í•œ ê° ì²­í¬ì˜ ìƒíƒœ(ëŒ€ê¸°, ì„±ê³µ ë“±) ë¦¬ìŠ¤íŠ¸.
        "is_running": False,            # í˜„ì¬ ë²ˆì—­ ì‘ì—…ì´ ì§„í–‰ ì¤‘ì¸ì§€ ì—¬ë¶€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í”Œë˜ê·¸(Flag).
        "context_guide": "",            # AIê°€ ìƒì„±í•˜ê³  ì‚¬ìš©ìê°€ ìˆ˜ì •í•œ ìµœì¢… ì»¨í…ìŠ¤íŠ¸ ê°€ì´ë“œ.
        "final_srt_content": "",        # ë²ˆì—­ ì™„ë£Œ í›„ ìµœì¢…ì ìœ¼ë¡œ ì¡°ë¦½ëœ SRT íŒŒì¼ ë‚´ìš©. ë‹¤ìš´ë¡œë“œ ë²„ê·¸ í•´ê²°ì˜ í•µì‹¬.
        "fetched_models": [],           # APIë¥¼ í†µí•´ ì¡°íšŒí•œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡.
        "original_content": None,       # ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ íŒŒì¼ì˜ ì›ë³¸ ë‚´ìš©.
        "uploaded_filename": None       # í˜„ì¬ ì—…ë¡œë“œëœ íŒŒì¼ì˜ ì´ë¦„. íŒŒì¼ ë³€ê²½ ê°ì§€ìš©.
    }
    # defaults ë”•ì…”ë„ˆë¦¬ë¥¼ ìˆœíšŒí•˜ë©°, ì„¸ì…˜ ìƒíƒœì— í•´ë‹¹ í‚¤ê°€ ì¡´ì¬í•˜ì§€ ì•Šì„ ê²½ìš°ì—ë§Œ ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”.
    # ì´ ì¡°ê±´ë¬¸ì´ ì—†ìœ¼ë©´, ì‚¬ìš©ìê°€ ì„¤ì •ì„ ë³€ê²½í•  ë•Œë§ˆë‹¤ ëª¨ë“  ìƒíƒœê°€ ì´ˆê¸°í™”ë˜ëŠ” ëŒ€ì°¸ì‚¬ê°€ ë°œìƒí•œë‹¤.
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value


# -----------------------------------------------------------------------------
# [3. ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œì§]
# ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì „ì²´ íë¦„ì„ ì œì–´í•˜ëŠ” í•¨ìˆ˜ë“¤.
# -----------------------------------------------------------------------------

def main():
    """
    ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œì§ì„ ì‹¤í–‰í•˜ëŠ” ì§„ì…ì (Entry Point) í•¨ìˆ˜.
    ì „ì²´ UI êµ¬ì¡°ë¥¼ ì •ì˜í•˜ê³ , ì‚¬ìš©ì ì´ë²¤íŠ¸ì— ë”°ë¼ ì ì ˆí•œ í•˜ìœ„ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ëŠ” ì´ê´„ ì§€íœ˜ì.
    """
    # st.set_page_configëŠ” ë°˜ë“œì‹œ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹œ ê°€ì¥ ë¨¼ì € í˜¸ì¶œë˜ì–´ì•¼ í•˜ëŠ” Streamlitì˜ ê·œì¹™.
    st.set_page_config(page_title="Ray's Subtitle Translator", layout="wide")
    # ì»¤ìŠ¤í…€ CSSë¥¼ HTML í—¤ë”ì— ì£¼ì….
    ui.load_css()
    # ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜ë“¤ì´ ì¤€ë¹„ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ìƒì„±.
    init_session_state()

    # --- 1. ì‚¬ì´ë“œë°” ì²˜ë¦¬ ---
    # ì‚¬ì´ë“œë°” UIë¥¼ ë Œë”ë§í•˜ê³ , ì‚¬ìš©ìì˜ í˜„ì¬ ì„¤ì •ê°’(settings)ê³¼ ë°œìƒí•œ ì´ë²¤íŠ¸(event)ë¥¼ ë°˜í™˜ë°›ëŠ”ë‹¤.
    # ì´ êµ¬ì¡°ëŠ” UI ì½”ë“œì™€ ë¡œì§ ì½”ë“œë¥¼ ë¶„ë¦¬í•˜ì—¬ app.pyë¥¼ ê¹”ë”í•˜ê²Œ ìœ ì§€í•œë‹¤.
    event, settings = ui.render_sidebar()
    api_key = settings.get("api_key")

    # ì‚¬ì´ë“œë°”ì—ì„œ ë°œìƒí•œ ì´ë²¤íŠ¸ì— ë”°ë¼ ì ì ˆí•œ í•¨ìˆ˜ë¥¼ í˜¸ì¶œ.
    if event == "check_models":
        handle_check_models(api_key)
    elif event == "stop_process":
        st.session_state["is_running"] = False
        st.warning("Stopping process... Please wait for the current chunk to finish.")
        st.rerun() # UIë¥¼ ì¦‰ì‹œ ê°±ì‹  (ì˜ˆ: ì •ì§€ ë²„íŠ¼ ìˆ¨ê¸°ê¸°)

    # --- 2. ë©”ì¸ í˜ì´ì§€ ì²˜ë¦¬ ---
    st.title("ğŸ¬ Subtitle Translator (Context-Aware)")
    uploaded_file = st.file_uploader("Upload Subtitle (.srt)", type=["srt"])

    # [ë°©ì–´ ì½”ë“œ 1] íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìœ¼ë©´, ë” ì´ìƒ ì§„í–‰í•˜ì§€ ì•Šê³  ì‚¬ìš©ìì—ê²Œ ì•ˆë‚´.
    if not uploaded_file:
        st.info("ğŸ‘ˆ Please upload an SRT file to begin.")
        return

    # [ë°©ì–´ ì½”ë“œ 2] API í‚¤ë‚˜ ëª¨ë¸ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìœ¼ë©´, ì§„í–‰ì„ ë§‰ê³  ì•ˆë‚´.
    if not api_key or not settings.get("selected_model"):
        st.warning("ğŸ‘ˆ Please enter your API Key and select a model in the sidebar.")
        return

    # --- 3. íŒŒì¼ ë‚´ìš© ì²˜ë¦¬ ë° ìºì‹± ---
    # ì‚¬ìš©ìê°€ ë™ì¼í•œ íŒŒì¼ì„ ê³„ì† ì˜¬ë ¤ë‘ê³  ë‹¤ë¥¸ ì„¤ì •ë§Œ ë°”ê¿€ ë•Œ, ë§¤ë²ˆ íŒŒì¼ì„ ë‹¤ì‹œ ì½ëŠ” ê²ƒì€ ë¹„íš¨ìœ¨ì .
    # íŒŒì¼ ì´ë¦„ì´ ë³€ê²½ë˜ì—ˆì„ ë•Œë§Œ íŒŒì¼ì„ ìƒˆë¡œ ì½ê³ , ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ì„¸ì…˜ì— ì €ì¥ëœ ë‚´ìš©ì„ ì¬ì‚¬ìš©í•œë‹¤. (ìµœì í™”)
    if uploaded_file.name != st.session_state.get("uploaded_filename"):
        st.session_state["uploaded_filename"] = uploaded_file.name
        bytes_data = uploaded_file.getvalue()
        encoding = core.detect_encoding(bytes_data) or 'utf-8' # ì¸ì½”ë”© ê°ì§€ ì‹¤íŒ¨ ì‹œ utf-8ë¡œ ì•ˆì „í•˜ê²Œ ëŒ€ì²´.
        st.session_state["encoding"] = encoding
        try:
            st.session_state["original_content"] = bytes_data.decode(encoding)
        except:
            # ìµœì¢… ë°©ì–´: ê·¸ë˜ë„ ë””ì½”ë”©ì— ì‹¤íŒ¨í•˜ë©´, ì†ìƒëœ ë¬¸ìëŠ” ë¬´ì‹œí•˜ê³  ê°•ì œë¡œ ë””ì½”ë”©.
            st.session_state["original_content"] = bytes_data.decode('utf-8', errors='ignore')
    
    content = st.session_state["original_content"]
    st.info(f"File loaded. Encoding: {st.session_state.get('encoding', 'unknown')}")

    # --- 4. UI ì„¹ì…˜ ë Œë”ë§ ë° ì´ë²¤íŠ¸ ì²˜ë¦¬ ---
    # ê° UI ì„¹ì…˜ì„ ë³„ë„ì˜ í•¨ìˆ˜ë¡œ ë¶„ë¦¬í•˜ì—¬ main í•¨ìˆ˜ì˜ ê°€ë…ì„± í™•ë³´.
    render_context_analysis_section(settings)
    
    # "ë²ˆì—­ ì‹œì‘" ë²„íŠ¼ì´ ëˆŒë¦¬ë©´, run_translation í•¨ìˆ˜ ì‹¤í–‰.
    if st.button("Start Translation Process", type="primary"):
        run_translation(content, settings)

    # ë²ˆì—­ì´ ì™„ë£Œë˜ì–´ 'ê¸ˆê³ 'ì— ìµœì¢… ê²°ê³¼ë¬¼ì´ ìˆì„ ê²½ìš°ì—ë§Œ ê²°ê³¼ ë° ìˆ˜ë¦¬ ì„¹ì…˜ì„ ë³´ì—¬ì¤Œ.
    if st.session_state.get("final_srt_content"):
        render_results_and_repair(content, settings)

def handle_check_models(api_key):
    """'ëª¨ë¸ ì¡°íšŒ' ë²„íŠ¼ í´ë¦­ ì´ë²¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜."""
    with st.spinner("Checking available models..."): # ì‚¬ìš©ìì—ê²Œ ì‘ì—… ì§„í–‰ ì¤‘ì„ì„ ì•Œë¦¬ëŠ” ìŠ¤í”¼ë„ˆ í‘œì‹œ.
        try:
            genai.configure(api_key=api_key)
            models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            st.session_state["fetched_models"] = models
            st.success(f"Found {len(models)} models!")
            time.sleep(1) # ì‚¬ìš©ìê°€ ì„±ê³µ ë©”ì‹œì§€ë¥¼ ì¸ì§€í•  ìˆ˜ ìˆë„ë¡ 1ì´ˆ ëŒ€ê¸°.
            st.rerun() # ëª¨ë¸ ëª©ë¡ì„ ì‚¬ì´ë“œë°” ë“œë¡­ë‹¤ìš´ì— ì¦‰ì‹œ ë°˜ì˜í•˜ê¸° ìœ„í•´ UIë¥¼ ê°•ì œ ìƒˆë¡œê³ ì¹¨.
        except Exception as e:
            st.error(f"Error checking models: {e}")

def render_context_analysis_section(settings):
    """ì»¨í…ìŠ¤íŠ¸ ë¶„ì„(Step 1) UI ì„¹ì…˜ì„ ë Œë”ë§í•˜ëŠ” í•¨ìˆ˜."""
    st.divider()
    st.subheader("ğŸ•µï¸ Step 1: Context Analysis (Optional)")
    col_a1, col_a2 = st.columns([1, 4]) # ë²„íŠ¼ê³¼ í…ìŠ¤íŠ¸ ì˜ì—­ì˜ ë¹„ìœ¨ì„ 1:4ë¡œ ì¡°ì ˆ.
    if col_a1.button("ğŸ§  Analyze Context"):
        with st.spinner("Analyzing..."):
            model = genai.GenerativeModel(settings["selected_model"])
            # core ëª¨ë“œì˜ ë¶„ì„ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ê²°ê³¼ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥.
            st.session_state["context_guide"] = core.analyze_context(model, st.session_state["original_content"], settings["src_lang"], settings["tgt_lang"])
        st.rerun() # ë¶„ì„ ê²°ê³¼ë¥¼ text_areaì— ì¦‰ì‹œ í‘œì‹œí•˜ê¸° ìœ„í•´ ìƒˆë¡œê³ ì¹¨.
    
    # ì‚¬ìš©ìê°€ AIì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì§ì ‘ ìˆ˜ì •í•  ìˆ˜ ìˆë„ë¡ text_area ì œê³µí•˜ê³ , ìˆ˜ì •í•œ ë‚´ìš©ì„ ë‹¤ì‹œ ì„¸ì…˜ ìƒíƒœì— ì €ì¥.
    st.session_state["context_guide"] = col_a2.text_area("Context Guide:", st.session_state["context_guide"], height=150)

def run_translation(content, settings):
    """ë²ˆì—­ ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•˜ê³  ì‹¤í–‰í•˜ëŠ” ë©”ì¸ ì›Œí¬í”Œë¡œìš° í•¨ìˆ˜."""
    # [1. ì´ˆê¸°í™”]
    st.session_state["is_running"] = True # ì‘ì—… ì‹œì‘ í”Œë˜ê·¸ë¥¼ ONìœ¼ë¡œ ì„¤ì •.
    parsed = core.parse_srt(content)
    if not parsed: # íŒŒì‹± ì‹¤íŒ¨ ì‹œ, ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œ í›„ ì‘ì—… ì¤‘ë‹¨.
        st.error("SRT parsing failed.")
        st.session_state["is_running"] = False
        return

    # íŒŒì‹± ë° ì²­í‚¹ ê²°ê³¼ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥.
    st.session_state.update({
        "parsed_srt": parsed,
        "chunks": core.chunk_text(parsed, settings["chunk_size"]),
    })
    
    total = len(st.session_state["chunks"])
    # ì´ì „ ì‘ì—…ì˜ ê²°ê³¼ê°€ ë‚¨ì•„ìˆì§€ ì•Šë„ë¡ ëª¨ë“  ê²°ê³¼ ê´€ë ¨ ìƒíƒœë¥¼ ê¹¨ë—í•˜ê²Œ ì´ˆê¸°í™”.
    st.session_state.update({
        "results": [None] * total, "debugs": [None] * total,
        "chunk_states": [{'status': 'WAITING', 'duration': 0} for _ in range(total)]
    })

    # [2. ì‹¤ì‹œê°„ UI ì¤€ë¹„]
    # st.empty()ë¡œ ë¹ˆ ê³µê°„(placeholder)ì„ ë§Œë“¤ì–´ë‘ë©´, ë‚˜ì¤‘ì— ì´ ê³µê°„ì˜ ë‚´ìš©ë§Œ ê³„ì† ë®ì–´ì“°ë©° ì—…ë°ì´íŠ¸ ê°€ëŠ¥.
    timer_ph, grid_ph, status_ph = st.empty(), st.empty(), st.empty()
    model = genai.GenerativeModel(settings["selected_model"])
    start_global = time.time()
    
    # [3. ë©”ì¸ ë²ˆì—­ ë£¨í”„]
    # ì»¨ë² ì´ì–´ ë²¨íŠ¸ ì‹œì‘. ì²­í¬ í•˜ë‚˜ì”© ìˆœíšŒí•˜ë©° ë²ˆì—­.
    for i, chunk in enumerate(st.session_state["chunks"]):
        # ë§¤ ë£¨í”„ ì‹œì‘ ì‹œ, 'ê¸´ê¸‰ ì •ì§€' ì‹ í˜¸ê°€ ì™”ëŠ”ì§€ í™•ì¸.
        if not st.session_state["is_running"]:
            status_ph.warning(f"Stopped at Chunk {i}.")
            break
        
        # [UI ì—…ë°ì´íŠ¸] í˜„ì¬ ì²­í¬ë¥¼ 'ì²˜ë¦¬ ì¤‘' ìƒíƒœë¡œ ë³€ê²½í•˜ê³ , ê·¸ë¦¬ë“œì™€ ìƒíƒœ ë©”ì‹œì§€ë¥¼ ë‹¤ì‹œ ê·¸ë¦¼.
        st.session_state["chunk_states"][i]['status'] = 'RUNNING'
        with grid_ph.container(): ui.render_grid(st.session_state["chunk_states"])
        status_ph.info(f"âš¡ Processing Chunk {i+1}/{total}...")
        
        # íƒ€ì´ë¨¸/ETA ê³„ì‚° ë° í‘œì‹œ.
        elapsed = time.time() - start_global
        avg_time = elapsed / (i + 1)
        eta = avg_time * (total - (i + 1))
        # ... (íƒ€ì´ë¨¸ ë Œë”ë§ ë¡œì§) ...
        
        # [í•µì‹¬ ë¡œì§ í˜¸ì¶œ]
        texts = [item['text'] for item in chunk]
        res, debug = core.translate_chunk(model, texts, settings["src_lang"], settings["tgt_lang"], 
                                         st.session_state["context_guide"], settings["enable_reasoning"])
        
        # [ê²°ê³¼ ì €ì¥]
        st.session_state["results"][i] = res
        st.session_state["debugs"][i] = debug
        st.session_state["chunk_states"][i]['status'] = 'SUCCESS' if debug['status'] == "Success" else 'ERROR'
        st.session_state["chunk_states"][i]['duration'] = debug.get('duration', 0)
        
        time.sleep(0.5) # API ì†ë„ ì œí•œ ë° ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ìµœì†Œí•œì˜ ì˜ˆì˜.
    
    # [4. ë§ˆë¬´ë¦¬]
    st.session_state["is_running"] = False # ì‘ì—… ì¢…ë£Œ í”Œë˜ê·¸ OFF.
    # ëª¨ë“  ë²ˆì—­ ê²°ê³¼ë¥¼ ìµœì¢… SRT ë¬¸ìì—´ë¡œ ì¡°ë¦½í•˜ì—¬ 'ê¸ˆê³ 'ì— ì €ì¥. ë‹¤ìš´ë¡œë“œ ë²„ê·¸ í•´ê²°ì˜ í•µì‹¬.
    st.session_state["final_srt_content"] = core.rebuild_srt(st.session_state["parsed_srt"], st.session_state["results"])
    st.rerun() # 'ì²˜ë¦¬ ì¤‘' í™”ë©´ì—ì„œ 'ê²°ê³¼' í™”ë©´ìœ¼ë¡œ ì „í™˜í•˜ê¸° ìœ„í•´ UI ìƒˆë¡œê³ ì¹¨.

def render_results_and_repair(content, settings):
    """ë²ˆì—­ ì™„ë£Œ í›„ ê²°ê³¼ í‘œì‹œ ë° ìˆ˜ë¦¬(Repair) UIë¥¼ ë Œë”ë§í•˜ëŠ” í•¨ìˆ˜."""
    st.divider()
    st.subheader("ğŸ“Š Execution Overview")
    ui.render_grid(st.session_state["chunk_states"])
    
    col_l, col_r = st.columns(2)
    col_l.text_area("Original", content, height=400)
    col_r.text_area("Translated", st.session_state["final_srt_content"], height=400)
        
    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì˜ ë°ì´í„°ëŠ” ë°˜ë“œì‹œ 'ê¸ˆê³ 'ì— ì €ì¥ëœ ìµœì¢… ê²°ê³¼ë¬¼ì„ ì‚¬ìš©.
    st.download_button("Download Result (.srt)", st.session_state["final_srt_content"].encode('utf-8'),
                        f"translated_{st.session_state.get('uploaded_filename', 'file.srt')}", type="primary")
    
    st.divider()
    st.subheader("ğŸ› ï¸ Chunk Inspector")
    
    for i, debug in enumerate(st.session_state["debugs"]):
        if not debug: continue
        is_success = debug['status'] == "Success"
        # ì‹¤íŒ¨í•œ ì²­í¬ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë©”ë‰´ë¥¼ í¼ì³ì„œ ë³´ì—¬ì¤Œ.
        with st.expander(f"{'âœ…' if is_success else 'âŒ'} Chunk {i+1}", expanded=not is_success):
            # [ì¬ì‹œë„ ë¡œì§]
            if st.button(f"ğŸ”„ Retry #{i+1}", key=f"retry_{i}"):
                with st.spinner("Retrying..."):
                    # í˜„ì¬ ì‚¬ì´ë“œë°”ì— ì„¤ì •ëœ ëª¨ë“  ê°’ì„ ì‚¬ìš©í•˜ì—¬ ì¬ì‹œë„.
                    model = genai.GenerativeModel(settings["selected_model"])
                    texts = [item['text'] for item in st.session_state["chunks"][i]]
                    
                    res, new_debug = core.translate_chunk(model, texts, **settings)
                    
                    # ì¬ì‹œë„ ê²°ê³¼ë¥¼ í•´ë‹¹ ì²­í¬ ì¸ë±ìŠ¤ì— ë®ì–´ì”€.
                    st.session_state["results"][i] = res
                    st.session_state["debugs"][i] = new_debug
                    st.session_state["chunk_states"][i].update({
                        'status': 'SUCCESS' if new_debug['status'] == "Success" else 'ERROR',
                        'duration': new_debug.get('duration', 0)
                    })
                    # 'ê¸ˆê³ 'ì˜ ë‚´ìš©ë„ ìƒˆë¡œìš´ ê²°ê³¼ë¡œ ì—…ë°ì´íŠ¸.
                    st.session_state["final_srt_content"] = core.rebuild_srt(st.session_state["parsed_srt"], st.session_state["results"])
                    # UIì— ë³€ê²½ì‚¬í•­ì„ ë°˜ì˜í•˜ê¸° ìœ„í•´ ë§ˆì§€ë§‰ì— í•œ ë²ˆë§Œ ìƒˆë¡œê³ ì¹¨.
                    st.rerun()

# --- ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ---
# ì´ íŒŒì¼ì´ 'python app.py' ëª…ë ¹ì–´ë¡œ ì§ì ‘ ì‹¤í–‰ë  ë•Œë§Œ main() í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•œë‹¤.
# ë‹¤ë¥¸ íŒŒì¼ì—ì„œ ì´ íŒŒì¼ì„ 'import app'ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¬ ë•ŒëŠ” ì‹¤í–‰ë˜ì§€ ì•ŠëŠ”ë‹¤ (íŒŒì´ì¬ì˜ í‘œì¤€ ì‹¤í–‰ ë°©ì‹).
if __name__ == "__main__":
    main()